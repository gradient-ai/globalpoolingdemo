{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  article dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from torchvision.utils import make_grid\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('Running on the GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Running on the CPU')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load in dataset\n",
    "\n",
    "We will use FashionMNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  loading training data\n",
    "training_set = Datasets.FashionMNIST(root='./', download=True,\n",
    "                                     transform=transforms.ToTensor())\n",
    "\n",
    "#  loading validation data\n",
    "validation_set = Datasets.FashionMNIST(root='./', download=True, train=False,\n",
    "                                       transform=transforms.ToTensor())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instantiate our ConvNets & Convolutional Neural Network class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvNet_1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.network = nn.Sequential(\n",
    "        #  layer 1\n",
    "        nn.Conv2d(1, 8, 3, padding=1),\n",
    "        nn.ReLU(),  # feature map size = (28, 28)\n",
    "        #  layer 2\n",
    "        nn.Conv2d(8, 8, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),  # feature map size = (14, 14)\n",
    "        #  layer 3\n",
    "        nn.Conv2d(8, 16, 3, padding=1),\n",
    "        nn.ReLU(),  # feature map size = (14, 14)\n",
    "        #  layer 4\n",
    "        nn.Conv2d(16, 16, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),  # feature map size = (7, 7)\n",
    "        #  layer 5\n",
    "        nn.Conv2d(16, 32, 3, padding=1),\n",
    "        nn.ReLU(),  # feature map size = (7, 7)\n",
    "        #  layer 6\n",
    "        nn.Conv2d(32, 32, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),  # feature map size = (3, 3)\n",
    "        #  output layer\n",
    "        nn.Conv2d(32, 10, 1),\n",
    "        nn.AvgPool2d(3)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, 1, 28, 28)\n",
    "    output = self.network(x)\n",
    "    output = output.view(-1, 10)\n",
    "    return torch.sigmoid(output)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvNet_2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.network = nn.Sequential(\n",
    "        #  layer 1\n",
    "        nn.Conv2d(1, 8, 3, padding=1),\n",
    "        nn.ReLU(),  # feature map size = (28, 28)\n",
    "        #  layer 2\n",
    "        nn.Conv2d(8, 8, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),  # feature map size = (14, 14)\n",
    "        #  layer 3\n",
    "        nn.Conv2d(8, 16, 3, padding=1),\n",
    "        nn.ReLU(),  # feature map size = (14, 14)\n",
    "        #  layer 4\n",
    "        nn.Conv2d(16, 16, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),  # feature map size = (7, 7)\n",
    "        #  layer 5\n",
    "        nn.Conv2d(16, 32, 3, padding=1),\n",
    "        nn.ReLU(),  # feature map size = (7, 7)\n",
    "        #  layer 6\n",
    "        nn.Conv2d(32, 32, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),  # feature map size = (3, 3)\n",
    "        #  output layer\n",
    "        nn.Conv2d(32, 10, 1),\n",
    "        nn.MaxPool2d(3)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, 1, 28, 28)\n",
    "    output = self.network(x)\n",
    "    output = output.view(-1, 10)\n",
    "    return torch.sigmoid(output)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvolutionalNeuralNet():\n",
    "  def __init__(self, network):\n",
    "    self.network = network.to(device)\n",
    "    self.optimizer = torch.optim.Adam(self.network.parameters(), lr=3e-4)\n",
    "\n",
    "  def train(self, loss_function, epochs, batch_size, \n",
    "            training_set, validation_set):\n",
    "    \n",
    "    #  creating log\n",
    "    log_dict = {\n",
    "        'training_loss_per_batch': [],\n",
    "        'validation_loss_per_batch': [],\n",
    "        'training_accuracy_per_epoch': [],\n",
    "        'validation_accuracy_per_epoch': []\n",
    "    } \n",
    "\n",
    "    #  defining weight initialization function\n",
    "    def init_weights(module):\n",
    "      if isinstance(module, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.fill_(0.01)\n",
    "\n",
    "    #  defining accuracy function\n",
    "    def accuracy(network, dataloader):\n",
    "      total_correct = 0\n",
    "      total_instances = 0\n",
    "      for images, labels in tqdm(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        predictions = torch.argmax(network(images), dim=1)\n",
    "        correct_predictions = sum(predictions==labels).item()\n",
    "        total_correct+=correct_predictions\n",
    "        total_instances+=len(images)\n",
    "      return round(total_correct/total_instances, 3)\n",
    "\n",
    "    #  initializing network weights\n",
    "    self.network.apply(init_weights)\n",
    "\n",
    "    #  creating dataloaders\n",
    "    train_loader = DataLoader(training_set, batch_size)\n",
    "    val_loader = DataLoader(validation_set, batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      print(f'Epoch {epoch+1}/{epochs}')\n",
    "      train_losses = []\n",
    "\n",
    "      #  training\n",
    "      print('training...')\n",
    "      for images, labels in tqdm(train_loader):\n",
    "        #  sending data to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        #  resetting gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        #  making predictions\n",
    "        predictions = self.network(images)\n",
    "        #  computing loss\n",
    "        loss = loss_function(predictions, labels)\n",
    "        log_dict['training_loss_per_batch'].append(loss.item())\n",
    "        train_losses.append(loss.item())\n",
    "        #  computing gradients\n",
    "        loss.backward()\n",
    "        #  updating weights\n",
    "        self.optimizer.step()\n",
    "      with torch.no_grad():\n",
    "        print('deriving training accuracy...')\n",
    "        #  computing training accuracy\n",
    "        train_accuracy = accuracy(self.network, train_loader)\n",
    "        log_dict['training_accuracy_per_epoch'].append(train_accuracy)\n",
    "\n",
    "      #  validation\n",
    "      print('validating...')\n",
    "      val_losses = []\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "          #  sending data to device\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          #  making predictions\n",
    "          predictions = self.network(images)\n",
    "          #  computing loss\n",
    "          val_loss = loss_function(predictions, labels)\n",
    "          log_dict['validation_loss_per_batch'].append(val_loss.item())\n",
    "          val_losses.append(val_loss.item())\n",
    "        #  computing accuracy\n",
    "        print('deriving validation accuracy...')\n",
    "        val_accuracy = accuracy(self.network, val_loader)\n",
    "        log_dict['validation_accuracy_per_epoch'].append(val_accuracy)\n",
    "\n",
    "      train_losses = np.array(train_losses).mean()\n",
    "      val_losses = np.array(val_losses).mean()\n",
    "\n",
    "      print(f'training_loss: {round(train_losses, 4)}  training_accuracy: '+\n",
    "      f'{train_accuracy}  validation_loss: {round(val_losses, 4)} '+  \n",
    "      f'validation_accuracy: {val_accuracy}\\n')\n",
    "      \n",
    "    return log_dict\n",
    "\n",
    "  def predict(self, x):\n",
    "    return self.network(x)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark your results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_1 = ConvolutionalNeuralNet(ConvNet_1())\n",
    "\n",
    "log_dict_1 = model_1.train(nn.CrossEntropyLoss(), epochs=60, batch_size=64,\n",
    "                           training_set=training_set, validation_set=validation_set)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.lineplot(y=log_dict_1['training_accuracy_per_epoch'], x=range(\n",
    "    len(log_dict_1['training_accuracy_per_epoch'])), label='training')\n",
    "\n",
    "sns.lineplot(y=log_dict_1['validation_accuracy_per_epoch'], x=range(\n",
    "    len(log_dict_1['validation_accuracy_per_epoch'])), label='validation')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_2 = ConvolutionalNeuralNet(ConvNet_2())\n",
    "\n",
    "log_dict_2 = model_2.train(nn.CrossEntropyLoss(), epochs=60, batch_size=64,\n",
    "                           training_set=training_set, validation_set=validation_set)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.lineplot(y=log_dict_2['training_accuracy_per_epoch'], x=range(\n",
    "    len(log_dict_2['training_accuracy_per_epoch'])), label='training')\n",
    "\n",
    "sns.lineplot(y=log_dict_2['validation_accuracy_per_epoch'], x=range(\n",
    "    len(log_dict_2['validation_accuracy_per_epoch'])), label='validation')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('maxpool_benchmark.png', dpi=1000)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Global Pooling Under the Hood\n",
    "\n",
    "a deeper look at why both global pooling methods work"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def visualize_layer(model, dataset, image_idx: int, layer_idx: int):\n",
    "  \"\"\"\n",
    "  This function visulizes intermediate layers in a convolutional neural \n",
    "  network defined using the PyTorch sequential class \n",
    "  \"\"\"\n",
    "  #  creating a dataloader\n",
    "  dataloader = DataLoader(dataset, 250)\n",
    "\n",
    "  #  deriving a single batch from dataloader\n",
    "  for images, labels in dataloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    break\n",
    "\n",
    "  #  deriving output from layer of interest\n",
    "  output = model.network.network[:layer_idx].forward(images[image_idx])\n",
    "  #  deriving output shape\n",
    "  out_shape = output.shape\n",
    "\n",
    "  #  classifying image\n",
    "  predicted_class = model.predict(images[image_idx])\n",
    "\n",
    "  print(\n",
    "      f'actual class: {labels[image_idx]}\\npredicted class: {torch.argmax(predicted_class)}')\n",
    "\n",
    "  #  visualising layer\n",
    "  plt.figure(dpi=150)\n",
    "  plt.title(f'visualising output')\n",
    "  plt.imshow(np.transpose(make_grid(output.cpu().view(out_shape[0], 1,\n",
    "                                                      out_shape[1],\n",
    "                                                      out_shape[2]),\n",
    "                                    padding=2, normalize=True), (1, 2, 0)))\n",
    "  plt.axis('off')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_1.network\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_layer(model=model_1, dataset=validation_set,\n",
    "                image_idx=2, layer_idx=16)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_layer(model=model_2, dataset=validation_set,\n",
    "                image_idx=2, layer_idx=16)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}